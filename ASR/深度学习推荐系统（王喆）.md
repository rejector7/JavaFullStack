
# 第2章　前深度学习时代——推荐系统的进化之路

## 2.1 传统推荐模型的演化关系图
读完第二章后可以用来总结：
![image](https://github.com/rejector7/JavaFullStack/assets/20394580/430856bb-4031-48bb-afa2-b6a471aa3319)

* 协同过滤分支：
  * UserCF
  * ItemCF
  * MF（矩阵分解）：给用户和商品生成隐向量
* 逻辑回归（LR）分支：
  * LR模型：融合除了用户和item之外的其他特征，比如上下文。
  * LS-PLM：聚类 + LR。类似注意力机制。
* 因子分解机（Factorization Machine）（特征交叉）分支：
  * PLOY2：特征两两交叉，赋予权重。参数量：n*2
  * FM：给每个特征生成隐向量。特征交叉权重 = 隐向量点乘。参数量 nk。隐向量k维。
  * FFM：基于FM引入特征域。每个特征生成f * k维的隐向量。f是域数。
* 组合模型：
  * GBDT+LR（梯度提升决策树(Gradient Boosting Decision Tree)+逻辑回归）
  * GBDT负责特征工程（可以捕捉高维特征），LR负责模型预测，二者分开训练。
 
**关注点**
* 特征信息量
* 权重参数量、训练复杂度。
* 可解释性

## 2.2 协同过滤——经典的推荐算法
## 2.3 矩阵分解算法——协同过滤的进化
## 2.4 逻辑回归——融合多种特征的推荐模型

**线性模型（Linear Model）&广义线性模型（Generalized Linear Model, GLM）**
LM&GLM主要部分有：
* 自变量线性组合（即LM）
* 因变量分布为指数族分布
* 链接函数，通过该函数将LM和因变量联系起来，拟合因变量分布。
通俗来讲，LM就是简单的线性组合，模型和任何一个自变量都是线性关系。而GLM就是将LM组合后的式子，通过一个指数型函数来拟合因变量的指数族分布。

**逻辑回归模型优势&局限性**
协同过滤只考虑用户/物品交互特征。
逻辑回归考虑用户、物品、上下文等任何单特征，只要作为线性模型的一个自变量即可。但没考虑特征交叉。

